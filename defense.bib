@inbook{greenberger1962management,
	title        = {{Management and the Computer of the Future}},
	author       = {McCarthy, John},
    editor       = {Greenberger, Martin},
	year         = 1962,
    month        = mar,
	publisher    = {M.I.T. Press and Wiley, New York},
	pages        = {220--236},
	lccn         = 62013234,
    isbn         = {9780262070041},
}

@book{wilder2012cloud,
  title={{Cloud Architecture Patterns: Using Microsoft Azure}},
  author={Wilder, Bill},
  year={2012},
  publisher={{O'Reilly Media, Inc.}}
}

@article{mellNISTDefinitionCloud,
	title        = {{The NIST Definition of Cloud Computing}},
	author       = {Peter Mell and Timothy Grance},
	year         = 2011,
	month        = sep,
	journal      = {National Institute of Standards and Technology Special Publication 800-145},
	doi          = {10.6028/NIST.SP.800-145},
	keywords     = {primary},
	langid       = {english}
}

@inproceedings{bitingoff_ghosh_2012,
	title        = {Biting {{Off Safely More Than You Can Chew}}: {{Predictive Analytics}} for {{Resource Over-Commit}} in {{IaaS Cloud}}},
	shorttitle   = {Biting {{Off Safely More Than You Can Chew}}},
	author       = {Ghosh, Rahul and Naik, Vijay K.},
	year         = 2012,
	month        = jun,
	booktitle    = {2012 {{IEEE Fifth International Conference}} on {{Cloud Computing}}},
	publisher    = {IEEE},
	address      = {Honolulu, HI, USA},
	pages        = {25--32},
	doi          = {10.1109/CLOUD.2012.131},
	abstract     = {Cloud service providers are constantly looking for ways to increase revenue and reduce costs either by reducing capacity requirements or by supporting more users without adding capacity. Over-commit of physical resources, without adding more capacity, is one such approach. Workloads that tend to be `peaky' are especially attractive targets for overcommit since only occasionally such workloads use all the system resources that they are entitled to. Online identification of candidate workloads and quantification of risks are two key issues associated with over-committing resources. In this paper, to estimate the risks associated with over-commit, we describe a mechanism based on the statistical analysis of the aggregate resource usage behavior of a group of workloads. Using CPU usage data collected from an internal private Cloud, we show that our proposed approach is effective and practical.},
	langid       = {english}
}

@article{armbrustViewCloudComputing2010,
  title = {A View of Cloud Computing},
  author = {Armbrust, Michael and Fox, Armando and Griffith, Rean and Joseph, Anthony D. and Katz, Randy and Konwinski, Andy and Lee, Gunho and Patterson, David and Rabkin, Ariel and Stoica, Ion and Zaharia, Matei},
  year = {2010},
  month = apr,
  journal = {Communications of the ACM},
  volume = {53},
  number = {4},
  pages = {50--58},
  doi = {10.1145/1721654.1721672},
  abstract = {Clearing the clouds away from the true potential and obstacles posed by this computing capability.},
  langid = {english},
}

@misc{Numerique40Budget2021,
  title = {{Num{\'e}rique : 40 \% du budget GES soutenable d'un europ{\'e}en}},
  shorttitle = {{Num{\'e}rique}},
  year = {2021},
  month = dec,
  journal = {Green IT},
  urldate = {2024-11-05},
  abstract = {Exclusif. Premi{\`e}re {\'e}tude sur la pollution num{\'e}rique en Europe et ses atteintes {\`a} l'environnement. Analyse du Cycle de Vie. {\'e}tude. 2021.},
  chapter = {Etude},
  howpublished = {https://www.greenit.fr/2021/12/08/numerique-40-du-budget-ges-soutenable-dun-europeen/},
  langid = {french},
}

@article{SchleierSmith2021WhatSC,
	title        = {{W}hat {S}erverless {C}omputing is and {S}hould {B}ecome: {T}he next {P}hase of {C}loud {C}omputing},
	author       = {Schleier-Smith, Johann and Sreekanti, Vikram and Khandelwal, Anurag and Carreira, Joao and Yadwadkar, Neeraja J. and Popa, Raluca Ada and Gonzalez, Joseph E. and Stoica, Ion and Patterson, David A.},
	year         = 2021,
	month        = apr,
	journal      = {Commun. ACM},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 64,
	number       = 5,
	pages        = {76â€“84},
	doi          = {10.1145/3406011},
	issue_date   = {May 2021},
	abstract     = {The evolution that serverless computing represents, the economic forces that shape it, why it could fail, and how it might fulfill its potential.},
	numpages     = 9
}

@inproceedings{hortaXartrekRuntimeExecution2021,
	title        = {{X}ar-{T}rek: {R}un-Time Execution Migration among {FPGA}s and {H}eterogeneous-{ISA} {CPU}s},
	shorttitle   = {{X}ar-{T}rek},
	author       = {Horta, Edson and Chuang, Ho-Ren and VSathish, Naarayanan Rao and Philippidis, Cesar and Barbalace, Antonio and Olivier, Pierre and Ravindran, Binoy},
	year         = 2021,
	month        = dec,
	booktitle    = {Proceedings of the 22nd {{International Middleware Conference}}},
	publisher    = {{ACM}},
	address      = {{Qu\'ebec city Canada}},
	pages        = {104--118},
	doi          = {10.1145/3464298.3493388},
	abstract     = {Datacenter servers are increasingly heterogeneous: from x86 host CPUs, to ARM or RISC-V CPUs in NICs/SSDs, to FPGAs. Previous works have demonstrated that migrating application execution at run-time across heterogeneous-ISA CPUs can yield significant performance and energy gains, with relatively little programmer effort. However, FPGAs have often been overlooked in that context: hardware acceleration using FPGAs involves statically implementing select application functions, which prohibits dynamic and transparent migration. We present Xar-Trek, a new compiler and run-time software framework that overcomes this limitation. Xar-Trek compiles an application for several CPU ISAs and select application functions for acceleration on an FPGA, allowing execution migration between heterogeneous-ISA CPUs and FPGAs at run-time. Xar-Trek's run-time monitors server workloads and migrates application functions to an FPGA or to heterogeneous-ISA CPUs based on a scheduling policy. We develop a heuristic policy that uses application workload profiles to make scheduling decisions. Our evaluations conducted on a system with x86-64 server CPUs, ARM64 server CPUs, and an Alveo accelerator card reveal 88\%-1\% performance gains over no-migration baselines.},
	langid       = {english}
}

@inproceedings{shahradServerlessWildCharacterizing,
	title        = {Serverless in the Wild: {C}haracterizing and Optimizing the Serverless Workload at a Large Cloud Provider},
	author       = {Shahrad, Mohammad and Fonseca, Rodrigo and Goiri, {\'I}{\~n}igo and Chaudhry, Gohar and Batum, Paul and Cooke, Jason and Laureano, Eduardo and Tresness, Colby and Russinovich, Mark and Bianchini, Ricardo},
	year         = 2020,
	booktitle    = {Proceedings of the 2020 USENIX Conference on Usenix Annual Technical Conference},
	publisher    = {USENIX Association},
	address      = {USA},
	series       = {USENIX ATC'20},
	pages        = 14,
	abstract     = {Function as a Service (FaaS) has been gaining popularity as a way to deploy computations to serverless backends in the cloud. This paradigm shifts the complexity of allocating and provisioning resources to the cloud provider, which has to provide the illusion of always-available resources (i.e., fast function invocations without cold starts) at the lowest possible resource cost. Doing so requires the provider to deeply understand the characteristics of the FaaS workload. Unfortunately, there has been little to no public information on these characteristics. Thus, in this paper, we first characterize the entire production FaaS workload of Azure Functions. We show for example that most functions are invoked very infrequently, but there is an 8-order-of-magnitude range of invocation frequencies. Using observations from our characterization, we then propose a practical resource management policy that significantly reduces the number of function cold starts, while spending fewer resources than state-of-the-practice policies.},
	langid       = {english},
	articleno    = 14,
	numpages     = 14,
}

@inproceedings{buyyaSLAorientedResourceProvisioning2011,
	title        = {{SLA}-oriented Resource Provisioning for Cloud Computing: {C}hallenges, Architecture, and Solutions},
	shorttitle   = {{SLA}-oriented Resource Provisioning for Cloud Computing},
	author       = {Buyya, Rajkumar and Garg, Saurabh Kumar and Calheiros, Rodrigo N.},
	year         = 2011,
	month        = dec,
	booktitle    = {2011 {I}nternational {C}onference on {C}loud and {S}ervice {C}omputing},
	publisher    = {{IEEE}},
	address      = {{Hong Kong, China}},
	pages        = {1--10},
	doi          = {10.1109/CSC.2011.6138522},
	abstract     = {Cloud computing systems promise to offer subscription-oriented, enterprise-quality computing services to users worldwide. With the increased demand for delivering services to a large number of users, they need to offer differentiated services to users and meet their quality expectations. Existing resource management systems in data centers are yet to support Service Level Agreement (SLA)-oriented resource allocation, and thus need to be enhanced to realize cloud computing and utility computing. In addition, no work has been done to collectively incorporate customer-driven service management, computational risk management, and autonomic resource management into a market-based resource management system to target the rapidly changing enterprise requirements of Cloud computing. This paper presents vision, challenges, and architectural elements of SLA-oriented resource management. The proposed architecture supports integration of marketbased provisioning policies and virtualisation technologies for flexible allocation of resources to applications. The performance results obtained from our working prototype system shows the feasibility and effectiveness of SLA-based resource provisioning in Clouds.},
	langid       = {english}
}

